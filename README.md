# Z-Stack-Annotation

This GUI was developed to address common challenges in biological image annotation, streamlining the process and enabling the creation of datasets for deep learning applications. 

This tool provides an intuitive and user-friendly platform for annotating large, multidimensional imaging datasets while overcoming limitations of existing software particularly in terms of automation, and data handling.

The GUI supports the annotation of 4D images (z-stacks with multiple color channels) and integrates data from a preprocessed .csv file generated by the nnU-Net model (3D nuclei segmentation repository). This file contains detailed information about nuclei positions and bounding box dimensions, allowing users to load the data directly into the GUI for visualization and manual refinement. 
</div>
Detected nuclei are displayed as bounding boxes overlaying the image, with the option to correct missed or misclassified instances. By blending automated and manual steps, the tool ensures accuracy and efficiency in data annotation.

<p align="center">
<img width="406" alt="Screenshot 2024-12-28 at 11 38 01" src="https://github.com/user-attachments/assets/6d4eedb4-3d36-4f06-8478-e24f796524f0" />
</p>

Two main types of classification are supported: morphological classification, tailored to specific experimental needs, and marker expression classification, which applies a more general binary scheme. Morphological categories are project-specific (i.e., round, branched, hBranched, cluster, other or unknown, reflecting the diverse phenotypes of astrocyte cultures in 3D hydrogels. Marker expression classification determines whether specific markers are present or absent in a cell, using a threshold-based semi-automatic approach. 

Predictions for marker presence are overly simplistic. The threshold-based method, which relies on the mean intensity within a bounding box, yields values exceeding eight times the mean intensity across the entire channel. This approach provides preliminary classifications that can be refined by the user.

<p align="center">
<img width="406" alt="Screenshot 2024-12-28 at 11 39 07" src="https://github.com/user-attachments/assets/4ec6f04c-1116-4d87-8f87-f6f3335dfedd" />
</p>

</div>

## TO DO
- Fix manual annotation tool
- Fix loading files order
- Improve semi-automatic marker prediction
- Include prediction model in the GUI
- Multipurpose interface
